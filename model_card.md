# Model Card for RecFusion

<!-- Provide a quick summary of what the model is/does. [Optional] -->
A Binomial / Gaussian Diffusion Process for 1D Data for Recommendation



# Model Details

## Model Description

<!-- Provide a longer summary of what this model is/does. -->
A Binomial / Gaussian Diffusion Process for 1D Data for Recommendation

- **Developed by:** Anonymized
- **Shared by [Optional]:** Anonymized
- **Model type:** Recommendation model
- **License:** unknown



# Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

## Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->
<!-- If the user enters content, print that. If not, but they enter a task in the list, use that. If neither, say "more info needed." -->

(i) non-sequential (ii) Top-$K$ recommendation with (iii) binary feedback


## Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->
<!-- If the user enters content, print that. If not, but they enter a task in the list, use that. If neither, say "more info needed." -->

Recommendation setups that violate assumptions (i)-(iii).


# Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

Significant research has explored bias and fairness issues with language models (see, e.g., [Sheng et al. (2021)](https://aclanthology.org/2021.acl-long.330.pdf) and [Bender et al. (2021)](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)). Predictions generated by the model may include disturbing and harmful stereotypes across protected classes; identity characteristics; and sensitive, social, and occupational groups.


# Training Details

## Training Data

<!-- This should link to a Data Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

MovieLens1M, MovieLens10M, MovieLens25M, Netflix


## Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

### Preprocessing

(i) filter out users with fewer than five items, and items with fewer than five interactions
(ii) Users are split into train, validation and test sets (0.8 / 0.1 / 0.1), with the training employing the entire history. For validation and test sets, a partial history is fed to the recommender, with a held-out set being used to evaluate the resulting recommendation. [a.k.a. strong generalization]
(iii) binarize feedback: ratings above 3 are encoded as 1, and zero otherwise.

 
# Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

## Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

Recall@20, Recall@50, NDCG@100

## Results 

| Dataset      | Model              | Recall@20 | Recall@50 | NDCG@100 |
|--------------|--------------------|-----------|-----------|----------|
| MovieLens25M | Random             | 0.13      | 0.30      | 0.24     |
|              | Popularity         | 16.63     | 24.43     | 19.69    |
|              | \textbf{RecFusion} | 33.21     | 45.44     | 37.31    |
|              | CODIGEM            | 34.05     | 45.84     | 37.90    |
|              | MultVAE            | 35.12     | 48.09     | 39.12    |
|              | EASE               | 40.02     | 52.71     | 43.84    |
| Netflix      | Random             | 0.18      | 0.32      | 0.31     |
|              | Popularity         | 11.73     | 17.48     | 15.89    |
|              | CODIGEM            | 25.54     | 33.48     | 29.08    |
|              | \textbf{RecFusion} | 29.68     | 37.63     | 32.87    |
|              | MultVAE            | 31.61     | 40.61     | 35.23    |
|              | EASE               | 36.19     | 44.49     | 39.35    |


# Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->

- **Hardware Type:** More information needed
- **Hours used:** ~ 200 (including hyperparameter tuning)
- **Cloud Provider:** Azure
- **Compute Region:** West Europe
- **Carbon Emitted:** ~ 35 kg CO2 eq.

Carbon emissions were estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

# Technical Specifications

## Model Architecture and Objective

Either one of MLP, MLP+T, MLP+Var, U-Net1D, U-Net2D

## Compute Infrastructure

Databricks ML clusters version 13 ML with sparktrials

# Citation

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

Anonymized

**APA:**

Anonymized

# Model Card Contact

Anonymized
